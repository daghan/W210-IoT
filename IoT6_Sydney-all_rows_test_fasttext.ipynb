{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IoT Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:8786\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787' target='_blank'>http://127.0.0.1:8787</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>16</li>\n",
       "  <li><b>Memory: </b>68.72 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://192.168.2.46:8786' processes=4 cores=16>"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from IPy import IP as IPy\n",
    "import pprint\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import csv\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from dask.distributed import Client, progress\n",
    "import dask.dataframe as dd\n",
    "client = Client('127.0.0.1:8786')\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Internet IP address <-> Organization mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASN_df = pd.read_csv(\"./ip2asn-combined.tsv\", sep='\\t', header=None)\n",
    "ASN_df.columns = ['start','end','asn','country','organization']\n",
    "\n",
    "# remove all the \"Not routed\" rows\n",
    "ASN_df = ASN_df[ASN_df['organization'] != 'Not routed']\n",
    "\n",
    "# add numerical representation for the start and end IP range for faster org search later\n",
    "ASN_df['start.dec'] = ASN_df['start'].apply(lambda x: float(IPy(x).strDec()))\n",
    "ASN_df['end.dec'] = ASN_df['end'].apply(lambda x: float(IPy(x).strDec()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device labeling  \n",
    "\n",
    "Makes the labels for the devices to be used later for supervised training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline \n",
    "tshark_cmd = \"-T fields -E header=y -e frame.number -e frame.time -e frame.len -e frame.protocols\"\n",
    "\n",
    "# ethernet layer\n",
    "#tshark_cmd += \" -e eth.src_resolved -e eth.dst_resolved\"\n",
    "tshark_cmd += \" -e eth.src -e eth.dst -e eth.dst_resolved\"\n",
    "\n",
    "#add IP/TCP/UDP/ICMP layers\n",
    "tshark_cmd += \" -e ip.src -e ip.dst -e tcp.srcport -e tcp.dstport -e udp.srcport -e udp.dstport\"\n",
    "\n",
    "# add DSN / mDNS layer\n",
    "tshark_cmd += \" -e dns.qry.name -e dns.resp.name -e dns.cname -e dns.a\"\n",
    "\n",
    "# add HTTP layer\n",
    "tshark_cmd += \" -e http.request.method -e http.request.uri -e http.user_agent -e http.host\"\n",
    "\n",
    "# add SSL certificate layer\n",
    "tshark_cmd += \" -e x509sat.printableString -e x509sat.uTF8String\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tshark -tud -N m -r ./packet_capture.pcap {tshark_cmd} > daghan.csv\n",
    "#!tshark -tud -N m -r ./IoT_Trafﬁc_UNSW_Sydney/train_large_2.pcap {tshark_cmd} > packets_train_large_2.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the packet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"./packets_train_large_2.csv\", sep='\\t')\n",
    "df = pd.read_csv(\"./packets_train_1M.csv\", sep='\\t')\n",
    "#df = pd.read_csv(\"./daghan.csv\", sep='\\t')\n",
    "#df = df.append(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load known devices labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUI_df = pd.read_csv('oui.csv')\n",
    "#known_devices = pd.read_csv('known_devices.csv')\n",
    "known_devices = pd.read_csv('sydney_devices.csv')\n",
    "\n",
    "\n",
    "\n",
    "known_devices['OUI'] = known_devices['MAC address'].apply(lambda x: ''.join(x.upper().split(':')[0:3]))\n",
    "known_devices['Manufacturer Device Type'] = ([' '.join(row) for row in \n",
    "                        zip(known_devices[\"Manufacturer\"],known_devices[\"Device Type\"])])\n",
    "known_devices['MAC address'] = known_devices['MAC address'].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"./packets_train_large_2.csv\", sep='\\t')\n",
    "df = pd.read_csv(\"./packets_train_1M.csv\", sep='\\t')\n",
    "#df = pd.read_csv(\"./daghan.csv\", sep='\\t')\n",
    "#df = df.append(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determineZone(ip):\n",
    "    \"\"\"\n",
    "    This function determines if the IP \n",
    "    address is internal or public \n",
    "    according to RFC1918\n",
    "    \"\"\"    \n",
    "    if pd.notna(ip):\n",
    "        return IPy(ip.split(',')[0]).iptype()\n",
    "    else:\n",
    "        return ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def protoLang(line):\n",
    "    proto = line['protocol'] \n",
    "    size = \"size: \" + str(line['frame.len'])\n",
    "    message = \"\"\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        ########################################\n",
    "        ### Extract base line protocol       ###\n",
    "        ########################################\n",
    "        \n",
    "        #UDP based?\n",
    "        if line['frame.protocols'].find('udp') > 0:     \n",
    "            src =  \" \".join(['device:',line['org.src'], 'identifier:', str(line['tail.src'])]) if line['zone.src'] == 'PRIVATE' \\\n",
    "                else \" \".join(['service:',line['org.src']])\n",
    "            srcport = 'port: ' + str(int(line['udp.srcport']))\n",
    "            dst =  \"\" if pd.isna(line['org.dst']) \\\n",
    "                    else (\" \".join(['device:', line['org.dst'],'identifier:', str(line['tail.dst'])]) if line['zone.dst'] == 'PRIVATE' \\\n",
    "                            else (\" \".join(['service:',line['org.src']]) if line['zone.dst'] == 'PUBLIC' else ''))\n",
    "            dstport = 'port: ' + str(int(line['udp.dstport']))\n",
    "        \n",
    "        #UDP based?\n",
    "        if line['frame.protocols'].find('tcp') > 0:     \n",
    "            src =  \" \".join(['device:',line['org.src'], 'identifier:', str(line['tail.src'])]) if line['zone.src'] == 'PRIVATE' \\\n",
    "                else \" \".join(['service:',line['org.src']])\n",
    "            srcport = 'port: ' + str(int(line['tcp.srcport']))\n",
    "            dst =  \"\" if pd.isna(line['org.dst']) \\\n",
    "                    else (\" \".join(['device:', line['org.dst'],'identifier:', str(line['tail.dst'])]) if line['zone.dst'] == 'PRIVATE' \\\n",
    "                            else (\" \".join(['service:',line['org.src']]) if line['zone.dst'] == 'PUBLIC' else ''))\n",
    "            dstport = 'port: ' + str(int(line['tcp.dstport']))\n",
    "        \n",
    "        ## ICMPv6\n",
    "        ## TODO: There is more information to be extracted here\n",
    "        elif proto == 'icmpv6':\n",
    "            src =  \" \".join([line['org.src'],line['tail.src']]) \n",
    "            return \" \".join(['device',src,proto,size]).lower()\n",
    "        \n",
    "        \n",
    "        #IP (L3) that is neither of those\n",
    "        elif line['frame.protocols'].find('ip') > 0:\n",
    "            src =  \" \".join(['device', line['org.src'],line['tail.src']]) if line['zone.src'] == 'PRIVATE' \\\n",
    "                    else \" \".join(['service', line['org.src']])\n",
    "            dst =  \"\" if pd.isna(line['org.dst']) \\\n",
    "                    else (\" \".join(['device', line['org.dst'],line['tail.dst']]) if line['zone.dst'] == 'PRIVATE' \\\n",
    "                            else (\" \".join(['service', line['org.src']]) if line['zone.dst'] == 'PUBLIC' else ''))\n",
    "        \n",
    "        #L2\n",
    "        elif line['frame.protocols'].find('ethertype') > 0:\n",
    "            src =  \" \".join(['device',line['org.src'],line['tail.src']]) \n",
    "            dst =  \" \".join(['device', line['org.dst'],line['tail.dst']]) if pd.notna(line['org.dst']) else ''\n",
    "        \n",
    "        #this should very rarely happen, if at all!\n",
    "        else:\n",
    "            print(\"undetected protocol(1): {}\".format(line))\n",
    "            return line['frame.protocols'].lower()\n",
    "        \n",
    "        \n",
    "        \n",
    "        ########################################\n",
    "        ### Extract higher layer protocol    ###\n",
    "        ### and additional meta data         ###\n",
    "        ########################################        \n",
    "         # x509ce (certificate exchange)\n",
    "        if line['frame.protocols'].find('x509') > 0:\n",
    "            proto = \"protocol: \" + proto\n",
    "            x509ce_message = ''\n",
    "            if pd.notna(line['x509sat.printableString']):\n",
    "                x509ce_message += line['x509sat.printableString']\n",
    "            if pd.notna(line['x509sat.uTF8String']):\n",
    "                x509ce_message += line['x509sat.uTF8String']\n",
    "            return \" \".join([src,srcport,proto,size,dst,dstport,x509ce_message]).lower()\n",
    "        \n",
    "        ## ssl \n",
    "        elif proto == 'ssl':\n",
    "            proto = \"protocol: \" + proto\n",
    "            return \" \".join([src,srcport,proto,size,dst,dstport]).lower()\n",
    "                \n",
    "        \n",
    "        ## tcp:data\n",
    "        elif line['frame.protocols'].find('tcp:data') > 0:\n",
    "            proto = \"protocol: tcp:data\"\n",
    "            return \" \".join([src,srcport,proto,size,dst,dstport]).lower()\n",
    "        \n",
    "        ## tcp:stun\n",
    "        ## TODO: stun.att.software \"stun.att.realm\": \"belkin.org\",\n",
    "        elif line['frame.protocols'].find('tcp:stun') > 0:\n",
    "            proto = 'protocol: tcp:stun'\n",
    "            return \" \".join([src,srcport,proto,size,dst,dstport]).lower()\n",
    "        \n",
    "        ## upd:data\n",
    "        ## TODO: Detect broadcasts\n",
    "        elif line['frame.protocols'].find('udp:data') > 0:\n",
    "            proto = 'protocol: udp:data'\n",
    "            return \" \".join([src,srcport,proto,size,dst,dstport]).lower()\n",
    "        \n",
    "        ## udp:nbns (netbios)\n",
    "        ## TODO: nbns.name\": \"MACBOOKAIR-7040<00> (Workstation\\/Redirector)\",\n",
    "        elif line['frame.protocols'].find('udp:nbns') > 0:\n",
    "            proto = 'protocol: udp:nbns'\n",
    "            return \" \".join([src,srcport,proto,size]).lower()\n",
    "        \n",
    "        ## upd:bootp (dhcp)\n",
    "        ## TODO: \"bootp.option.hostname\": \"amazon-c4475da2a\"\n",
    "        ## TODO: \"bootp.type\": \"2\" (1 is request, 2 is reply)\n",
    "        ## if it is a reply, add the dst IP address too\n",
    "        elif line['frame.protocols'].find('udp:bootp') > 0:\n",
    "            proto = 'protocol: udp:bootp'\n",
    "            return \" \".join([src,srcport,proto,size]).lower()\n",
    "        \n",
    "        ## udP:gquic\n",
    "        ## TODO: \"gquic.tag.sni\": \"0.docs.google.com\"\n",
    "        ## TODO: \"gquic.tag.uaid\": \"Chrome\\/65.0.3325.181 Intel Mac OS X 10_13_3\" \n",
    "        ## TODO: \"gquic.tag\": \"CHLO\" (client hello)\n",
    "        elif line['frame.protocols'].find('udp:quic') > 0:\n",
    "            proto = 'protocol: udp:gquic'\n",
    "            return \" \".join([src,srcport,proto,size,dst,dstport]).lower()\n",
    "        \n",
    "        ## ssdp (simple service discovery protocol)\n",
    "        ## TODO: http.server: \"Linux UPnP\\/1.0 Sonos\\/41.3-50131 (ZPS12)\n",
    "        ## TODO: http.unknown_header: \"HOUSEHOLD.SMARTSPEAKER.AUDIO: Sonos_hOcMvZ0JBvDVZz7BXZc5ILQAT5.Cd7MOjIUy3HWHWEXItIZ\\\\r\\\\n\",\n",
    "        ## TODO: http.request.full_uri: \"http:\\/\\/239.255.255.250:1900*\",\n",
    "        elif proto == 'ssdp':\n",
    "            proto = \"protocol: \" + proto\n",
    "            return \" \".join([src,srcport,proto,size,dst,dstport]).lower()\n",
    "        \n",
    "        ## db-lsp-disc:json (Dropbox Lan sync Discovery Protocol)\n",
    "        ## TODO: Detect and use Broadcast\n",
    "        ## TODO: eth.addr_resolved\": \"Broadcast\"\n",
    "        elif line['frame.protocols'].find('db-lsp-disc:json') > 0:\n",
    "            proto = 'protocol: db-lsp-disc'\n",
    "            return \" \".join([src,srcport,proto,size,dstport]).lower()\n",
    "        \n",
    "        ## ntp (network time protocol)\n",
    "        elif proto == 'ntp':\n",
    "            proto = \"protocol: \" + proto\n",
    "            return \" \".join([src,srcport,proto,size,dst,dstport]).lower()\n",
    "        \n",
    "        ## STP (spanning tree protocol)\n",
    "        elif proto == 'stp':\n",
    "            proto = \"protocol: \" + proto\n",
    "            return \" \".join([src,proto,size]).lower()\n",
    "        \n",
    "        ## mdns\n",
    "        elif proto == 'mdns':\n",
    "            proto = \"protocol: \" + proto\n",
    "            mdns_string =   (line['dns.qry.name'] + \" \" if pd.notna(line['dns.qry.name']) else '') + \\\n",
    "                            (line['dns.resp.name'] + \" \" if pd.notna(line['dns.resp.name']) else '') +\\\n",
    "                            (line['dns.cname'] + \" \" if pd.notna(line['dns.cname']) else '') + \\\n",
    "                            (line['dns.a'] if pd.notna(line['dns.a']) else '')    \n",
    "            return \" \".join([src,srcport,proto,size,mdns_string]).lower()\n",
    "        \n",
    "        ## igmp\n",
    "        ##TODO: look into IGMP\n",
    "        elif proto == 'igmp':\n",
    "            proto = \"protocol: \" + proto\n",
    "            return \" \".join([src,proto,dst]).lower()\n",
    "        \n",
    "        ## dns\n",
    "        elif proto == 'dns':\n",
    "            proto = \"protocol: \" + proto\n",
    "            dns_string =   (line['dns.qry.name'] + \" \" if pd.notna(line['dns.qry.name']) else '') + \\\n",
    "                            (line['dns.resp.name'] + \" \" if pd.notna(line['dns.resp.name']) else '') +\\\n",
    "                            (line['dns.cname'] + \" \" if pd.notna(line['dns.cname']) else '') + \\\n",
    "                            (line['dns.a'] if pd.notna(line['dns.a']) else '')\n",
    "            return \" \".join([src,srcport,proto,size,dst,dstport,dns_string]).lower()\n",
    "\n",
    "        ## http \n",
    "        elif proto == 'http':\n",
    "            proto = \"protocol: \" + proto\n",
    "            payload = (line['http.request.method'] + \" \" if pd.notna(line['http.request.method']) else '') + \\\n",
    "                    (line['http.request.uri'] + \" \" if pd.notna(line['http.request.uri']) else '') + \\\n",
    "                    (line['http.user_agent'] + \" \" if pd.notna(line['http.user_agent']) else '') + \\\n",
    "                    (line['http.host'] if pd.notna(line['http.host']) else '')\n",
    "            return \" \".join([src,srcport,proto,size,dst,dstport,payload]).lower()\n",
    "        \n",
    "        ## http:data\n",
    "        ## TODO: add http.file_data content\n",
    "        elif line['frame.protocols'].find('http:data') > 0:\n",
    "            proto = 'protocol: http:data'\n",
    "            payload = (line['http.request.method'] + \" \" if pd.notna(line['http.request.method']) else '') + \\\n",
    "                    (line['http.request.uri'] + \" \" if pd.notna(line['http.request.uri']) else '') + \\\n",
    "                    (line['http.user_agent'] + \" \" if pd.notna(line['http.user_agent']) else '') + \\\n",
    "                    (line['http.host'] if pd.notna(line['http.host']) else '')\n",
    "            return \" \".join([src,srcport,proto,size,dst,dstport,payload]).lower()\n",
    "        \n",
    "        ## http:media\n",
    "        ## TODO: add  http.content_type , http.content_length\n",
    "        elif line['frame.protocols'].find('http:media') > 0:\n",
    "            proto = 'protocol: http:media'\n",
    "            return \" \".join([src,srcport,proto,size,dst,dstport]).lower()\n",
    "        \n",
    "        \n",
    "        ## icmp:data\n",
    "        ## TODO: Consider adding icmp.type to the frame / protocol language\n",
    "        ## TODO: Detect broadcast\n",
    "        elif line['frame.protocols'].find('icmp:data') > 0:\n",
    "            proto = 'protocol: icmp:data'\n",
    "            return \" \".join([src,proto,size,dst]).lower()\n",
    "        \n",
    "        elif proto == 'arp':\n",
    "            #return \" \".join([src,proto,size,dst])\n",
    "            return \"\".lower()\n",
    "        \n",
    "        ## ethertype:data\n",
    "        elif line['frame.protocols'].find('ethertype:data') > 0:\n",
    "            proto = 'protocol: ethertype:data'\n",
    "            return \" \".join([src,proto,size]).lower()\n",
    "        \n",
    "        # undetected protocols\n",
    "        else:\n",
    "            #is it based on UDP or TCP?\n",
    "            proto = \"protocol: \" + proto\n",
    "            if line['frame.protocols'].find('udp') +\\\n",
    "                line['frame.protocols'].find('tcp') > 0:\n",
    "                return \" \".join([src,srcport,proto,size,dst,dstport]).lower()\n",
    "            elif line['frame.protocols'].find('ip')> 0:\n",
    "                return \" \".join([src,proto,size,dst]).lower()\n",
    "            elif line['frame.protocols'].find('ethertype')> 0:\n",
    "                return \" \".join([src,proto,size,dst]).lower()\n",
    "            else:\n",
    "                print(\"undetected protocol(2): {}\".format(str(line)))\n",
    "                return \" \".join([src,proto,size,dst]).lower()\n",
    "            \n",
    "    except ValueError:\n",
    "        print('Exception!!')\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessDF(df):\n",
    "    df['oui.src'] = df['eth.src'].apply(lambda x: ''.join(x.upper().split(':')[0:3]))\n",
    "    df['tail.src'] = df['eth.src'].apply(lambda x: ''.join(x.upper().split(':')[3:6]))\n",
    "    df['oui.dst'] = df['eth.dst'].apply(lambda x: ''.join(x.upper().split(':')[0:3]))\n",
    "    df['tail.dst'] = df['eth.dst'].apply(lambda x: ''.join(x.upper().split(':')[3:6]))\n",
    "    \n",
    "    #create dask frame\n",
    "    df = dd.from_pandas(df, npartitions=8)\n",
    "    \n",
    "    #add OUI\n",
    "    df = df.merge(OUI_df[list(['Assignment', 'Organization Name'])], \n",
    "             left_on = 'oui.src',  right_on= 'Assignment', how = 'left').drop(['Assignment'], axis = 1)\n",
    "    df = df.rename(columns={'Organization Name':'org.src'})\n",
    "\n",
    "    df = df.merge(OUI_df[list(['Assignment', 'Organization Name'])], \n",
    "             left_on = 'oui.dst',  right_on= 'Assignment', how = 'left').drop(['Assignment'], axis = 1)\n",
    "    df = df.rename(columns={'Organization Name':'org.dst'})\n",
    "    \n",
    "    # let's get rid of white spaces\n",
    "    df['org.src'] = df['org.src'].apply(lambda x: x.replace('.','').replace(',','').replace(\" \", \"-\") if pd.notna(x) else x, meta = str)\n",
    "    df['org.dst'] = df['org.dst'].apply(lambda x: x.replace('.','').replace(',','').replace(\" \", \"-\") if pd.notna(x) else x, meta = str)\n",
    "    \n",
    "    # clean up org and tail for dst columns\n",
    "    df['org.dst'] = df['org.dst'].fillna('')\n",
    "    df['tail.dst'] = df[['org.dst','tail.dst','eth.dst_resolved']].apply(lambda row: row['tail.dst'] if (row['org.dst'] != '') \\\n",
    "                                                                     else row['eth.dst_resolved'], axis = 1, meta = str)\n",
    "    # adding private (local) and public (internet) traffic zones\n",
    "    df['zone.src'] = df['ip.src'].apply(lambda x: determineZone(x), meta = str)\n",
    "    df['zone.dst'] = df['ip.dst'].apply(lambda x: determineZone(x), meta = str)\n",
    "    \n",
    "    # clean up IP addresses that have multiple source or dest values\n",
    "    df['ip.src'] = df['ip.src'].apply(lambda x: x.split(',')[0] if pd.notna(x) else x, meta = str)\n",
    "    df['ip.dst'] = df['ip.dst'].apply(lambda x: x.split(',')[0] if pd.notna(x) else x, meta = str)\n",
    "    \n",
    "    # the communication protocol column\n",
    "    df['protocol'] = df['frame.protocols'].apply(lambda x: x.split(':')[-1], meta = str)\n",
    "    \n",
    "    # create a list of public IP addresses that we need to resolve\n",
    "    public_IPs = set()\n",
    "    public_IPs_orgs = {}\n",
    "    for index,row in df.iterrows():\n",
    "        if (row['zone.src'] == \"PUBLIC\"):\n",
    "            public_IPs.add(row['ip.src'])\n",
    "        if (row['zone.dst'] == \"PUBLIC\"):\n",
    "            public_IPs.add(row['ip.dst'])\n",
    "    \n",
    "    # let's look up these public IP addresses in our db and replace with the service name\n",
    "    for ip in public_IPs:\n",
    "        try:\n",
    "            public_IPs_orgs[ip] = ASN_df[(ASN_df['start.dec'] <= float(IPy(ip).strDec())) & \n",
    "                                    (ASN_df['end.dec'] >= float(IPy(ip).strDec()))]['organization']\\\n",
    "                                    .values[0].split(' ')[0]\n",
    "        except:\n",
    "            #print(ip)\n",
    "            public_IPs_orgs[ip] = 'UNLISTED'\n",
    "\n",
    "    # let's replace org data for public IPs based on the ASN information\n",
    "    df['org.src'] = df[['zone.src','ip.src','org.src']].apply(lambda x: ( public_IPs_orgs[x['ip.src']] if x['zone.src'] == \"PUBLIC\" else x['org.src']), axis=1, meta = str)\n",
    "    df['org.dst'] = df[['zone.dst','ip.dst','org.dst']].apply(lambda x: ( public_IPs_orgs[x['ip.dst']] if x['zone.dst'] == \"PUBLIC\" else x['org.dst']), axis=1, meta = str)\n",
    "   \n",
    "    #df['org.src'] = df['org.src'].fillna(\"UNKNOWN\")\n",
    "    #df['tail.src'] = df['tail.src'].fillna(\"UNKNOWN\")\n",
    "    #df['org.dst'] = df['org.dst'].fillna(\"UNKNOWN\")\n",
    "    #df['tail.dst'] = df['tail.dst'].fillna(\"UNKNOWN\")\n",
    "    \n",
    "     # let's create a sentence for each packet\n",
    "    df['sentence'] = df.apply(lambda line: protoLang(line), axis=1, meta = str)\n",
    "    \n",
    "    \n",
    "    # Aggregating these sentences for each device is non-trivial. \n",
    "    # More can be found here: \n",
    "    # https://docs.google.com/spreadsheets/d/1UCClhmFm9nZc6VUr5XV_rMtQ90C3vgFb4nJ6DG2iF_g\n",
    "    \n",
    "    # Or just read on! \n",
    "    \n",
    "    # Source   Destination\n",
    "    # Private  Private   => L3: Local device to local device (this one is actually very tricky, refer to the link above)\n",
    "    # Private  Public    => L3: Local device to Internet\n",
    "    # Public   Private   => L3: Internet to local device, register for the eth.dst\n",
    "    # Public   Public    => Shouldn't be possible, ignore\n",
    "    # NaN      whatever  => If the source device has no public or private zone (therefore NaN), that means it doesn't have \n",
    "    #                       an IP address, which means it is almost certainly layer 2 (ethernet traffic)\n",
    "    #                       L2: Local device to local device, register for eth.src         \n",
    "\n",
    "    # 3 aggregation\n",
    "    # 1- source = Private (local to local and local to Internet, register for eth.src)\n",
    "    # 2- source = Public  (Internet to local, register for the eth.dst)\n",
    "    # 3- source = NA  (L2, the local device can be the receiver or sender, register for eth.src)\n",
    "\n",
    "\n",
    "    \n",
    "    df_agg1 = df[(df['zone.src'] == 'PRIVATE') & (df['sentence'] != '')][['eth.src','sentence']]\n",
    "    df_agg2 = df[(df['zone.src'] == 'PUBLIC')  & (df['sentence'] != '')][['eth.dst','sentence']]\n",
    "    df_agg2.columns = ['eth.src','sentence']\n",
    "    df_agg3 = df[(df['zone.src'] != 'PRIVATE') & (df['zone.src'] != 'PUBLIC') & (df['sentence'] != '')][['eth.src','sentence']]\n",
    "\n",
    "    final_agg = df_agg1.append(df_agg2)#.append(df_agg3)\n",
    "    return final_agg.append(df_agg3)\n",
    "    #return df_agg3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_agg_df = preprocessDF(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_agg_df.compute().to_csv('step2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ind.index\n",
    "print(len(final_agg_df))\n",
    "final_agg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_agg_df = final_agg_df.merge(known_devices[list(['MAC address','Manufacturer Device Type'])], \n",
    "             left_on = 'eth.src',  right_on= 'MAC address', how = 'inner').drop(['MAC address'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(final_merged_df))\n",
    "print(len(final_agg_df))\n",
    "final_agg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_agg_df.compute().to_csv(\"syndey_test_full2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_agg_df['Manufacturer Device Type'].compute().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = final_agg_df[['Manufacturer Device Type', 'sentence']].compute()\n",
    "#total_df.columns = ['label', 'sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(total_df['Manufacturer Device Type'])\n",
    "total_df['label'] = le.transform(total_df['Manufacturer Device Type'])\n",
    "total_df = total_df.drop(['Manufacturer Device Type'], axis=1)\n",
    "#total_df['label'] = total_df['label'].apply(lambda x: '__label__' + str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df[total_df['label'] == '__label__2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(total_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('fast_train7.txt', header=None, index=None, sep=' ')\n",
    "test.to_csv('fast_test7.txt', header=None, index=None, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 1 fast_train7.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!../fastText/fasttext supervised -input fast_train7.txt -output model7 -label  __label__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!../fastText/fasttext test model7.bin fast_test7.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 1 fast_test7.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = pd.read_csv('fast_test7.txt', header = None, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "#label_df['check'] = test[0]\n",
    "label_df['check'] = test['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = label_df.replace({'__label__':''}, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df['conf'] = label_df['check'] + ' ' + label_df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df['conf'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df['conf'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>check</th>\n",
       "      <th>conf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [0, 1, check, conf]\n",
       "Index: []"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df[label_df['conf'] == '26 26'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Belkin-International-Inc 832811 49153 tcp 66 Belkin-International-Inc 79F489 3256'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[1].iloc[167]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Belkin-International-Inc 832811 49153 tcp 66 Belkin-International-Inc 79F489 4941'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[1].iloc[520]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Belkin-International-Inc 832811 4800 tcp 74 Belkin-International-Inc 79F489 49153'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[1].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Belkin-International-Inc 79F489 49153 tcp 66 Belkin-International-Inc 832811 3555'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[1].iloc[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
